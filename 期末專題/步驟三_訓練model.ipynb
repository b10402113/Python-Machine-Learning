{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <font color=#0099ff size=6 face=\"黑体\">步驟3 - 訓練model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "創立model完成後，我們可以開始創建訓練的model\n",
    "</font>\n",
    "\n",
    "<font color=#1a2933  size=5 face=\"黑体\">一、引入必須套件</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.image_data_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=5 face=\"黑体\">二、創建一個新的model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">第一個隱藏層一樣告訴 Keras 我們輸入長什麼樣子。padding 設成 same 是每個 filter 會輸出原來 96x96 一樣大小的矩陣。\n",
    "    \n",
    "filter為32個大小為3x3</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=(96,96,3)))\n",
    "model.add(Activation(\"relu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 加入Batch Normalization\n",
    "Batch Normalization 在進行學習時以 mini-batch 為單位，依照各個 mini-batch 來進行正規化。為了增加神經網絡的穩定性，它透過減去 batch 的均值並除以 batch 的標準差（standard deviation）來正規化前面激活層（activation）的輸出。\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(BatchNormalization(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### pool與dropout\n",
    "Dropout 25% 並將池化層size設定為3 * 3\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 從32->64->128增加層數\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=-1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最後一層為10因為我們有十種\n",
    "model.add(Dense(10))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 96, 96, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 96, 96, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 96, 96, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              8389632   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 8,683,402\n",
      "Trainable params: 8,680,522\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 引入數據\n",
    "使用pickle將之前保存的數據讀出\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(\"tl_data.pickle\",\"rb\")\n",
    "tl_data = pickle.load(pickle_in)\n",
    "pickle_in = open(\"tl_labels.pickle\",\"rb\")\n",
    "tl_labels = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10226, 96, 96, 3)\n",
      "(10226, 10)\n"
     ]
    }
   ],
   "source": [
    "print(tl_data.shape)\n",
    "print(tl_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 分成trainX 和 testX\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainX, testX, trainY, testY) = train_test_split(tl_data,tl_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### ImageDataGenerator\n",
    "產生更多不同的圖片\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "255/255 [==============================] - 281s 1s/step - loss: 2.5335 - acc: 0.2654 - val_loss: 2.1521 - val_acc: 0.3631\n",
      "Epoch 2/30\n",
      "255/255 [==============================] - 276s 1s/step - loss: 2.1088 - acc: 0.3499 - val_loss: 2.1849 - val_acc: 0.3768\n",
      "Epoch 3/30\n",
      "255/255 [==============================] - 276s 1s/step - loss: 1.9214 - acc: 0.3950 - val_loss: 2.2319 - val_acc: 0.3534\n",
      "Epoch 4/30\n",
      "255/255 [==============================] - 275s 1s/step - loss: 1.7055 - acc: 0.4474 - val_loss: 1.5750 - val_acc: 0.4844\n",
      "Epoch 5/30\n",
      "255/255 [==============================] - 275s 1s/step - loss: 1.5970 - acc: 0.4822 - val_loss: 1.6261 - val_acc: 0.4751\n",
      "Epoch 6/30\n",
      "255/255 [==============================] - 279s 1s/step - loss: 1.5027 - acc: 0.5058 - val_loss: 1.6593 - val_acc: 0.4873\n",
      "Epoch 7/30\n",
      "255/255 [==============================] - 271s 1s/step - loss: 1.3890 - acc: 0.5406 - val_loss: 1.1482 - val_acc: 0.6119\n",
      "Epoch 8/30\n",
      "255/255 [==============================] - 272s 1s/step - loss: 1.3173 - acc: 0.5650 - val_loss: 1.2137 - val_acc: 0.6163\n",
      "Epoch 9/30\n",
      "255/255 [==============================] - 272s 1s/step - loss: 1.2574 - acc: 0.5786 - val_loss: 1.3338 - val_acc: 0.5630\n",
      "Epoch 10/30\n",
      "255/255 [==============================] - 272s 1s/step - loss: 1.2421 - acc: 0.5887 - val_loss: 1.3132 - val_acc: 0.5635\n",
      "Epoch 11/30\n",
      "255/255 [==============================] - 280s 1s/step - loss: 1.1617 - acc: 0.6111 - val_loss: 1.2182 - val_acc: 0.6114\n",
      "Epoch 12/30\n",
      "255/255 [==============================] - 267s 1s/step - loss: 1.1118 - acc: 0.6337 - val_loss: 1.3307 - val_acc: 0.5777\n",
      "Epoch 13/30\n",
      "255/255 [==============================] - 265s 1s/step - loss: 1.1289 - acc: 0.6315 - val_loss: 1.1926 - val_acc: 0.6373\n",
      "Epoch 14/30\n",
      "255/255 [==============================] - 264s 1s/step - loss: 1.0955 - acc: 0.6447 - val_loss: 1.2909 - val_acc: 0.5885\n",
      "Epoch 15/30\n",
      "255/255 [==============================] - 263s 1s/step - loss: 1.0872 - acc: 0.6436 - val_loss: 1.0889 - val_acc: 0.6471\n",
      "Epoch 16/30\n",
      "255/255 [==============================] - 275s 1s/step - loss: 1.0143 - acc: 0.6672 - val_loss: 1.1922 - val_acc: 0.6153\n",
      "Epoch 17/30\n",
      "255/255 [==============================] - 267s 1s/step - loss: 0.9857 - acc: 0.6758 - val_loss: 0.9819 - val_acc: 0.6896\n",
      "Epoch 18/30\n",
      "255/255 [==============================] - 264s 1s/step - loss: 0.9479 - acc: 0.6925 - val_loss: 1.0638 - val_acc: 0.6588\n",
      "Epoch 19/30\n",
      "255/255 [==============================] - 265s 1s/step - loss: 0.9482 - acc: 0.6855 - val_loss: 1.0210 - val_acc: 0.6691\n",
      "Epoch 20/30\n",
      "255/255 [==============================] - 271s 1s/step - loss: 0.9138 - acc: 0.6959 - val_loss: 0.9979 - val_acc: 0.6823\n",
      "Epoch 21/30\n",
      "255/255 [==============================] - 265s 1s/step - loss: 0.8780 - acc: 0.7068 - val_loss: 0.9351 - val_acc: 0.7092\n",
      "Epoch 22/30\n",
      "255/255 [==============================] - 275s 1s/step - loss: 0.8766 - acc: 0.7133 - val_loss: 0.8888 - val_acc: 0.7219\n",
      "Epoch 23/30\n",
      "255/255 [==============================] - 269s 1s/step - loss: 0.8490 - acc: 0.7174 - val_loss: 1.1331 - val_acc: 0.6413\n",
      "Epoch 24/30\n",
      "255/255 [==============================] - 268s 1s/step - loss: 0.8408 - acc: 0.7213 - val_loss: 1.1298 - val_acc: 0.6447\n",
      "Epoch 25/30\n",
      "255/255 [==============================] - 269s 1s/step - loss: 0.8003 - acc: 0.7350 - val_loss: 0.8489 - val_acc: 0.7336\n",
      "Epoch 26/30\n",
      "255/255 [==============================] - 276s 1s/step - loss: 0.7699 - acc: 0.7475 - val_loss: 0.9372 - val_acc: 0.7033\n",
      "Epoch 27/30\n",
      "255/255 [==============================] - 287s 1s/step - loss: 0.7812 - acc: 0.7404 - val_loss: 0.8128 - val_acc: 0.7532\n",
      "Epoch 28/30\n",
      "255/255 [==============================] - 274s 1s/step - loss: 0.7634 - acc: 0.7513 - val_loss: 0.8695 - val_acc: 0.7405\n",
      "Epoch 29/30\n",
      "255/255 [==============================] - 267s 1s/step - loss: 0.7533 - acc: 0.7499 - val_loss: 0.7968 - val_acc: 0.7537\n",
      "Epoch 30/30\n",
      "255/255 [==============================] - 270s 1s/step - loss: 0.7159 - acc: 0.7684 - val_loss: 1.2379 - val_acc: 0.6119\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "BatchSize = 32 \n",
    "INIT_LR = 1e-3\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BatchSize),validation_data=(testX, testY),steps_per_epoch=len(trainX) // BatchSize,epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tlc.model\")\n",
    "model.save(\"tlc.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 引入數據\n",
    "使用pickle將之前保存的數據讀出\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入imutils 的paht，他可以幫我們把所有的圖片之檔名列出\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"tlc.model\")\n",
    "model2.save(\"tlc.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046/2046 [==============================] - 25s 12ms/step\n",
      "測試資料的 loss: 0.86442\n",
      "測試資料的正確率: 0.7663734113599082\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testY)\n",
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "    \n",
    "### 再訓練十五次\n",
    "上述可知，正確率已達到0.77，因此我們更新model後再次訓練十五次\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "255/255 [==============================] - 290s 1s/step - loss: 0.4763 - acc: 0.8391 - val_loss: 0.8589 - val_acc: 0.7698\n",
      "Epoch 2/15\n",
      "255/255 [==============================] - 296s 1s/step - loss: 0.4365 - acc: 0.8524 - val_loss: 0.7690 - val_acc: 0.7908\n",
      "Epoch 3/15\n",
      "255/255 [==============================] - 287s 1s/step - loss: 0.4269 - acc: 0.8555 - val_loss: 0.7489 - val_acc: 0.7981\n",
      "Epoch 4/15\n",
      "255/255 [==============================] - 275s 1s/step - loss: 0.4195 - acc: 0.8597 - val_loss: 0.7728 - val_acc: 0.7923\n",
      "Epoch 5/15\n",
      "255/255 [==============================] - 273s 1s/step - loss: 0.4111 - acc: 0.8596 - val_loss: 0.9081 - val_acc: 0.7581\n",
      "Epoch 6/15\n",
      "255/255 [==============================] - 287s 1s/step - loss: 0.4318 - acc: 0.8534 - val_loss: 0.8197 - val_acc: 0.7771\n",
      "Epoch 7/15\n",
      "255/255 [==============================] - 269s 1s/step - loss: 0.3986 - acc: 0.8630 - val_loss: 0.7754 - val_acc: 0.7864\n",
      "Epoch 8/15\n",
      "255/255 [==============================] - 282s 1s/step - loss: 0.4068 - acc: 0.8628 - val_loss: 0.7067 - val_acc: 0.8128\n",
      "Epoch 9/15\n",
      "255/255 [==============================] - 272s 1s/step - loss: 0.3948 - acc: 0.8691 - val_loss: 0.8669 - val_acc: 0.7742\n",
      "Epoch 10/15\n",
      "255/255 [==============================] - 264s 1s/step - loss: 0.3926 - acc: 0.8662 - val_loss: 0.8240 - val_acc: 0.7805\n",
      "Epoch 11/15\n",
      "255/255 [==============================] - 273s 1s/step - loss: 0.3790 - acc: 0.8700 - val_loss: 0.7925 - val_acc: 0.8011\n",
      "Epoch 12/15\n",
      "255/255 [==============================] - 262s 1s/step - loss: 0.4002 - acc: 0.8668 - val_loss: 0.9138 - val_acc: 0.7493\n",
      "Epoch 13/15\n",
      "255/255 [==============================] - 288s 1s/step - loss: 0.3978 - acc: 0.8611 - val_loss: 0.8621 - val_acc: 0.7713\n",
      "Epoch 14/15\n",
      "255/255 [==============================] - 274s 1s/step - loss: 0.3950 - acc: 0.8670 - val_loss: 0.7662 - val_acc: 0.8011\n",
      "Epoch 15/15\n",
      "255/255 [==============================] - 283s 1s/step - loss: 0.3563 - acc: 0.8795 - val_loss: 0.7566 - val_acc: 0.8069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5f9c85f8>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 15\n",
    "BatchSize = 32 \n",
    "model2 = model\n",
    "model.fit_generator(aug.flow(trainX, trainY, batch_size=BatchSize),\n",
    "                    validation_data=(testX, testY),steps_per_epoch=len(trainX) // BatchSize,\n",
    "                    epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2046/2046 [==============================] - 23s 11ms/step\n",
      "測試資料的 loss: 0.75657\n",
      "測試資料的正確率: 0.8069403717478233\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testX, testY)\n",
    "print(f'測試資料的 loss: {score[0]:.5f}')\n",
    "print(f'測試資料的正確率: {score[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"tlc.model\")\n",
    "model.save(\"tlc.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#1a2933  size=5 face=\"黑体\">五、 總結</font>\n",
    "\n",
    "<font color=#1a2933  size=3 face=\"黑体\">\n",
    "\n",
    "訓練花了我非常久的時間，一次訓練要4分鐘，\n",
    "最後準確率有達到80%\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
